{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90159,"status":"ok","timestamp":1683082119156,"user":{"displayName":"aws research","userId":"16991543843945014661"},"user_tz":-600},"id":"90eKpuuxktMj","outputId":"b88fe690-9dab-4d1b-92bc-a5502d844eac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.dgl.ai/wheels/repo.html\n","Collecting dgl-cu116\n","  Downloading https://data.dgl.ai/wheels/dgl_cu116-0.9.1.post1-cp310-cp310-manylinux1_x86_64.whl (246.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.3/246.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dglgo\n","  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl-cu116) (3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl-cu116) (4.65.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl-cu116) (1.10.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl-cu116) (1.22.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl-cu116) (5.9.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl-cu116) (2.27.1)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n","Collecting ruamel.yaml>=0.17.20\n","  Downloading ruamel.yaml-0.17.22-py3-none-any.whl (107 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpydoc>=1.1.0\n","  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting isort>=5.10.1\n","  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ogb>=1.3.3\n","  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting autopep8>=1.6.0\n","  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n","Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.7)\n","Collecting pycodestyle>=2.10.0\n","  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n","Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n","Collecting sphinx>=4.2\n","  Downloading sphinx-7.0.0-py3-none-any.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting outdated>=0.2.0\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.15)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.0+cu118)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl-cu116) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl-cu116) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl-cu116) (2.0.12)\n","Collecting ruamel.yaml.clib>=0.2.6\n","  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.2)\n","Collecting littleutils\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n","Collecting docutils<0.20,>=0.18.1\n","  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n","Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n","Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n","Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n","Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n","Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n","Building wheels for collected packages: littleutils\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=f6fb53bf6331b2a48a88f025df505d6f27184be8c1745c5865ac3b180443df10\n","  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n","Successfully built littleutils\n","Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, dgl-cu116, autopep8, numpydoc, ogb, dglgo\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.16\n","    Uninstalling docutils-0.16:\n","      Successfully uninstalled docutils-0.16\n","  Attempting uninstall: sphinx\n","    Found existing installation: Sphinx 3.5.4\n","    Uninstalling Sphinx-3.5.4:\n","      Successfully uninstalled Sphinx-3.5.4\n","Successfully installed autopep8-2.0.2 dgl-cu116-0.9.1.post1 dglgo-0.0.2 docutils-0.19 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.22 ruamel.yaml.clib-0.2.7 sphinx-7.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting iteration-utilities==0.11.0\n","  Downloading iteration_utilities-0.11.0.tar.gz (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: iteration-utilities\n","  Building wheel for iteration-utilities (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iteration-utilities: filename=iteration_utilities-0.11.0-cp310-cp310-linux_x86_64.whl size=380681 sha256=b39bdd681a99fedd0fef5372f4b4a175fb627a592649f118e4f9c9578ebf578c\n","  Stored in directory: /root/.cache/pip/wheels/2d/ab/c4/309aa5942beba1f36d6744acf619b7a314fca50f6a7ccce68c\n","Successfully built iteration-utilities\n","Installing collected packages: iteration-utilities\n","Successfully installed iteration-utilities-0.11.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece==0.1.98\n","  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.98\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers==0.13.3\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.13.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.28.1\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.65.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.13.3)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2022.10.31)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (23.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2022.12.7)\n","Installing collected packages: huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentence-transformers==2.2.2\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.28.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.65.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.15.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.22.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.1.98)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.14.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.4.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.27.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.5.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers==2.2.2) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers==2.2.2) (16.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.12)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=bfba8c70356097b0ac0deb35a553ad7b834f4aa8b8d34b2b3a3a6066c1ff2dce\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built sentence-transformers\n","Installing collected packages: sentence-transformers\n","Successfully installed sentence-transformers-2.2.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scipy==1.8.0\n","  Downloading scipy-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scipy==1.8.0) (1.22.4)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.10.1\n","    Uninstalling scipy-1.10.1:\n","      Successfully uninstalled scipy-1.10.1\n","Successfully installed scipy-1.8.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting networkx==2.6\n","  Downloading networkx-2.6-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from networkx==2.6) (1.22.4)\n","Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from networkx==2.6) (1.5.3)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from networkx==2.6) (3.7.1)\n","Requirement already satisfied: scipy!=1.6.1,>=1.5 in /usr/local/lib/python3.10/dist-packages (from networkx==2.6) (1.8.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (23.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (1.4.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (4.39.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (8.4.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->networkx==2.6) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->networkx==2.6) (1.16.0)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'networkx' candidate (version 2.6 at https://files.pythonhosted.org/packages/b2/87/30ed9e62d5459bbf22b335fc2d9d1faf979d44b1c55a1f0455da0afd756e/networkx-2.6-py3-none-any.whl (from https://pypi.org/simple/networkx/) (requires-python:>=3.7))\n","Reason for being yanked: Need to resolve: https://github.com/networkx/networkx/pull/4967\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: networkx\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.1\n","    Uninstalling networkx-3.1:\n","      Successfully uninstalled networkx-3.1\n","Successfully installed networkx-2.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pingouin==0.5.3\n","  Downloading pingouin-0.5.3-py3-none-any.whl (198 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (0.8.10)\n","Requirement already satisfied: seaborn>=0.11 in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (0.12.2)\n","Collecting pandas-flavor>=0.2.0\n","  Downloading pandas_flavor-0.5.0-py3-none-any.whl (7.1 kB)\n","Requirement already satisfied: outdated in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (0.2.2)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (1.8.0)\n","Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (0.13.5)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (1.22.4)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (1.5.3)\n","Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (3.7.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pingouin==0.5.3) (1.2.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin==0.5.3) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin==0.5.3) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin==0.5.3) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin==0.5.3) (4.39.3)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin==0.5.3) (8.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin==0.5.3) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin==0.5.3) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin==0.5.3) (3.0.9)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pingouin==0.5.3) (2022.7.1)\n","Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from pandas-flavor>=0.2.0->pingouin==0.5.3) (2022.12.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from pandas-flavor>=0.2.0->pingouin==0.5.3) (0.2)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->pingouin==0.5.3) (0.5.3)\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin==0.5.3) (67.7.2)\n","Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin==0.5.3) (0.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin==0.5.3) (2.27.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pingouin==0.5.3) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pingouin==0.5.3) (1.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin==0.5.3) (1.16.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin==0.5.3) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin==0.5.3) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin==0.5.3) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin==0.5.3) (3.4)\n","Installing collected packages: pandas-flavor, pingouin\n","Successfully installed pandas-flavor-0.5.0 pingouin-0.5.3\n"]}],"source":["!pip install dgl-cu116 dglgo -f https://data.dgl.ai/wheels/repo.html\n","!pip install iteration-utilities==0.11.0\n","!pip install sentencepiece==0.1.98\n","!pip install tokenizers==0.13.3\n","!pip install transformers==4.28.1\n","!pip install sentence-transformers==2.2.2\n","!pip install scipy==1.8.0 \n","!pip install networkx==2.6\n","!pip install pingouin==0.5.3"]},{"cell_type":"markdown","source":["In this work, we use google drive as file system. Please connect to your own Google Drive."],"metadata":{"id":"Z1nDVE7S3qWU"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31126,"status":"ok","timestamp":1683082150279,"user":{"displayName":"aws research","userId":"16991543843945014661"},"user_tz":-600},"id":"pKFpDAdmkzCe","outputId":"61776554-6fed-433a-ef39-7bf87ddfed43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at drive\n"]}],"source":["from google.colab import drive\n","!mkdir drive\n","drive.mount('drive')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5723,"status":"ok","timestamp":1683082156000,"user":{"displayName":"aws research","userId":"16991543843945014661"},"user_tz":-600},"id":"5kTyxDIZkXFj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d59b9da-5114-4d9c-bc1a-d9bbb23637b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]},{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]}],"source":["import pandas as pd\n","import dgl\n","from dgl.data import DGLDataset\n","import torch\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","import glob\n","import subprocess\n","import csv\n","import numpy as np\n","import pickle\n","from iteration_utilities import unique_everseen\n","import itertools\n","import sentencepiece as spm\n","import transformers\n","import tokenizers\n","from transformers import PreTrainedTokenizerFast,PreTrainedTokenizer\n","from tokenizers import SentencePieceBPETokenizer\n","import scipy.sparse as sp\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import roc_auc_score\n","from sentence_transformers import SentenceTransformer, util\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","import statistics\n","import random\n","import math\n","import warnings\n","warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')\n","\n","# set your file url here \n","url = ''\n","base_url = './drive/MyDrive/' + url \n","seed = 2\n","k = 5"]},{"cell_type":"markdown","source":["We concentrate on two installations: Chromium and Qt"],"metadata":{"id":"4HZ26H7P4FZu"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"r_W-y0Pkja-Y","executionInfo":{"status":"ok","timestamp":1683073990213,"user_tz":-600,"elapsed":6,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"outputs":[],"source":["projects = [\"chromium\",'qt']"]},{"cell_type":"markdown","source":["Generate GNN graph"],"metadata":{"id":"kPD6R8vdlU2P"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"UlrTTRpWze14","executionInfo":{"status":"ok","timestamp":1683074056588,"user_tz":-600,"elapsed":360,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"outputs":[],"source":["def generateGraphGNN(project):\n","    print(project)\n","    # Load pre-trained sentencepiece model\n","    pre_tokenizer = PreTrainedTokenizerFast(tokenizer_file=f'{base_url}/tokenizer/tokenizer.model', model_max_length=512, pad_token =\"<pad>\")\n","    train_dir_path = f'{base_url}/dataset/{project}/train/'\n","\n","    files = [f for f in listdir(train_dir_path) if isfile(join(train_dir_path, f))]\n","\n","    for file in files:\n","        project_name = '-'.join(file.split('-')[:-1])\n","        with open(f'{base_url}/dataset/{project}/train/{file}', 'rb') as f:\n","            content = pickle.load(f)\n","            edges_src = []\n","            edges_dst = []\n","            node_code = []\n","            node_label = []\n","            n_nodes = 0\n","\n","            for review_item in content:\n","                review_function = []\n","                for function in review_item:\n","                    single_function_name = function['function_name']\n","                    single_function_code = function['code']\n","                    single_file_name = \"-\".join(function['file'].split(\"-\")[1:-1])\n","                    unique_function_string = f\"{single_function_name} {single_function_code} {single_file_name}\"\n","                    function_label = function['label']\n","                    function_idx = function['function_idx']\n","                    if function_idx not in review_function:\n","                        review_function.append(function_idx)\n","\n","                    \n","                    if unique_function_string not in node_code:\n","                        node_code.append(unique_function_string)\n","                        node_label.append(function_label)\n","                        if function_idx >= n_nodes:\n","                            n_nodes = function_idx + 1\n","                function_perm = list(itertools.combinations(review_function, 2))\n","                edges_src += [e[0] for e in function_perm]\n","                edges_dst += [e[1] for e in function_perm]\n","            \n","            # convert the textual information of code functions into vectors\n","            node_feature_tensor = pre_tokenizer(node_code,max_length=512,padding=True, truncation=True, return_tensors='pt')[\"input_ids\"]\n","            node_label_tensor = torch.tensor(node_label)\n","            edge_src_tensor = torch.tensor(edges_src)\n","            edge_dst_tensor = torch.tensor(edges_dst)\n","            graph = dgl.graph((edges_src, edges_dst), num_nodes=n_nodes)\n","            graph.ndata['feat'] = node_feature_tensor\n","            graph.ndata['label'] = node_label_tensor\n","        with open(f\"{base_url}/gnn-graph/{project}/{file}-graph.pkl\", 'wb') as f:\n","            pickle.dump(graph, f)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"B305FXcw07ND","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682389653209,"user_tz":-600,"elapsed":228915,"user":{"displayName":"aws research","userId":"16991543843945014661"}},"outputId":"e02067de-5a11-41c2-9fe3-8b2cf044ada0"},"outputs":[{"output_type":"stream","name":"stdout","text":["chromium\n","qt\n"]}],"source":["for project in projects:\n","    generateGraphGNN(project)"]},{"cell_type":"markdown","metadata":{"id":"Ijzn7q4PDAAA"},"source":["GraphSage configuration"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"CVxgsl_0fl08","executionInfo":{"status":"ok","timestamp":1683074063077,"user_tz":-600,"elapsed":1,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"outputs":[],"source":["import dgl.function as fn\n","from dgl.nn import SAGEConv\n","import random\n","seed = 2\n","def setup_seed(seed):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    dgl.seed(seed)\n","    dgl.random.seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","device = 'cpu'\n","\n","class GraphSAGE(nn.Module):\n","    def __init__(self, in_feats, h_feats):\n","        super(GraphSAGE, self).__init__()\n","        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n","        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n","\n","    def forward(self, g, in_feat):\n","        h = self.conv1(g, in_feat)\n","        h = F.relu(h)\n","        h = self.conv2(g, h)\n","        return h\n","        \n","class DotPredictor(nn.Module):\n","    def forward(self, g, h):\n","        with g.local_scope():\n","            g.ndata['h'] = h\n","            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n","            return g.edata['score'][:, 0]\n","\n","def compute_loss(pos_score, neg_score):\n","    scores = torch.cat([pos_score, neg_score])\n","    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n","    return F.binary_cross_entropy_with_logits(scores, labels)\n","\n","def compute_auc(pos_score, neg_score):\n","    scores = torch.cat([pos_score, neg_score]).numpy()\n","    labels = torch.cat(\n","        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n","    return roc_auc_score(labels, scores)"]},{"cell_type":"markdown","source":["Generate node embeddings for the knowledge graph using GraphSage model"],"metadata":{"id":"iQPOC6Ga4uSt"}},{"cell_type":"code","execution_count":30,"metadata":{"id":"FcgyCRxDeW-T","executionInfo":{"status":"ok","timestamp":1682389653210,"user_tz":-600,"elapsed":26,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"outputs":[],"source":["def generateEmbedding(project):\n","    print(project)\n","    seed = 2\n","    test_dir_path = f'{base_url}/gnn-graph/{project}/'\n","    files = [f for f in listdir(test_dir_path) if isfile(join(test_dir_path, f))]\n","    setup_seed(seed)\n","    error = []\n","    for file in files:\n","        project_name = '-'.join(file.split('-')[:-2])\n","        print(file)\n","        with open(f'{base_url}/gnn-graph/{project}/{file}', 'rb') as f:\n","            g = pickle.load(f)\n","            g.to(device)\n","            u,v = g.edges()\n","            eids = np.arange(g.number_of_edges())\n","            np.random.seed(seed)\n","            eids = np.random.permutation(eids)\n","            valid_size = int(len(eids) * 0.1)\n","            train_size = g.number_of_edges() - valid_size\n","            test_pos_u, test_pos_v = u[eids[:valid_size]], v[eids[:valid_size]]\n","            train_pos_u, train_pos_v = u[eids[valid_size:]], v[eids[valid_size:]]\n","            adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())), shape=(g.number_of_nodes(),g.number_of_nodes()))\n","            adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n","            neg_u, neg_v = np.where(adj_neg != 0)\n","            neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n","            test_neg_u, test_neg_v = neg_u[neg_eids[:valid_size]], neg_v[neg_eids[:valid_size]]\n","            train_neg_u, train_neg_v = neg_u[neg_eids[valid_size:]], neg_v[neg_eids[valid_size:]]\n","            train_g = dgl.remove_edges(g, eids[:valid_size])\n","            train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n","            train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n","\n","            test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n","            test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n","            model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n","            model = model.to(device)\n","            pred = DotPredictor()\n","            \n","            optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n","            \n","            train_g = train_g.to(device)\n","            train_pos_g = train_pos_g.to(device)\n","            train_neg_g = train_neg_g.to(device)\n","            test_pos_g = test_pos_g.to(device)\n","            test_neg_g = test_neg_g.to(device)\n","\n","            all_logits = []\n","            min_auc = 0\n","\n","            early_stop = 0\n","            best_h = h = model(train_g, train_g.ndata['feat'].float())\n","\n","            for e in range(100):\n","                h = model(train_g, train_g.ndata['feat'].float())\n","                pos_score = pred(train_pos_g, h)\n","                neg_score = pred(train_neg_g, h)\n","                loss = compute_loss(pos_score, neg_score)\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                with torch.no_grad():\n","                    pos_score = pred(test_pos_g, h)\n","                    neg_score = pred(test_neg_g, h)\n","                    auc = compute_auc(pos_score, neg_score)\n","                    if auc > min_auc:\n","                        min_auc = auc\n","                        best_h = h\n","                        early_stop = 0\n","                    else:\n","                        early_stop += 1\n","\n","                if early_stop == 5:\n","                    break\n","        with open(f'{base_url}/node_embedding/{project}/{project_name}-embedding.pkl', 'wb') as f:\n","            pickle.dump(best_h, f)"]},{"cell_type":"markdown","metadata":{"id":"DsX2H1sp5DUa"},"source":["Please use premium GPU for training, otherwise it may occur \"out of memory error\""]},{"cell_type":"code","execution_count":31,"metadata":{"id":"9ld6SXelPQX2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682389932492,"user_tz":-600,"elapsed":279307,"user":{"displayName":"aws research","userId":"16991543843945014661"}},"outputId":"d6ce2b3c-e4d9-4b90-ea66-2aa8aed841df"},"outputs":[{"output_type":"stream","name":"stdout","text":["chromium\n","chromium-angle_2Fangle-train.pkl-graph.pkl\n","chromium-aosp_2Fplatform_2Fsystem_2Fupdate_engine-train.pkl-graph.pkl\n","chromium-chromiumos_2Fplatform_2Fec-train.pkl-graph.pkl\n","chromium-chromiumos_2Fplatform2-train.pkl-graph.pkl\n","chromium-chromiumos_2Fthird_party_2Fflashrom-train.pkl-graph.pkl\n","chromium-v8_2Fv8-train.pkl-graph.pkl\n","qt\n","qt-qt_2Fqtwayland-train.pkl-graph.pkl\n","qt-qt_2Fqtwebengine-train.pkl-graph.pkl\n","qt-qbs_2Fqbs-train.pkl-graph.pkl\n","qt-qt_2Fqtquick3d-train.pkl-graph.pkl\n","qt-qt3dstudio_2Fqt3d-runtime-train.pkl-graph.pkl\n","qt-qt_2Fqtbase-train.pkl-graph.pkl\n","qt-installer-framework_2Finstaller-framework-train.pkl-graph.pkl\n","qt-qt_2Fqtquickcontrols2-train.pkl-graph.pkl\n","qt-qt3dstudio_2Fqt3dstudio-train.pkl-graph.pkl\n","qt-qt_2Fqt3d-train.pkl-graph.pkl\n","qt-qt-creator_2Fqt-creator-train.pkl-graph.pkl\n","qt-qt_2Fqtdeclarative-train.pkl-graph.pkl\n"]}],"source":["for project in projects:\n","    generateEmbedding(project)"]},{"cell_type":"markdown","source":["Evaluation"],"metadata":{"id":"rJHm7mptTapo"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"I2H6EiShBxpQ","executionInfo":{"status":"ok","timestamp":1683081908130,"user_tz":-600,"elapsed":23,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"outputs":[],"source":["# generate the results using CoChangeFinder\n","def getResult(project):\n","    dir_path = f'{base_url}/node_embedding/{project}/'\n","    projects = [f for f in listdir(dir_path) if isfile(join(dir_path, f))] \n","    graph_result = {}\n","    for subproject in projects:\n","        project_name = '-'.join(subproject.split('-')[:-1])\n","\n","        with open(f\"{base_url}/node_embedding/{project}/{project_name}-embedding.pkl\", 'rb') as nf:\n","            best_h = pickle.load(nf)\n","            best_h = F.normalize(best_h,p=2, dim=1)\n","        with open(f'{base_url}/gnn-graph/{project}/{project_name}-train.pkl-graph.pkl', 'rb') as f:\n","            g = pickle.load(f)\n","        with open(f\"{base_url}/dataset/{project}/test/{project_name}-test.pkl\", 'rb') as f:\n","            test_data = pickle.load(f)\n","            project_score = []\n","            h_feature = best_h.size()[1]\n","            co_change_embedding = torch.zeros(1, h_feature)\n","            result = []\n","            for data in test_data:\n","                co_changed_data = [element['function_idx'] for element in data[\"co-change\"]]\n","                target_data = [(element['function_idx'],element['label']) for element in data[\"to-predict\"]]\n","                for function_idx in co_changed_data:\n","                    co_change_embedding = torch.add(co_change_embedding, best_h[function_idx])\n","                target_embedding = []\n","                \n","                target_score = []\n","                for target in target_data: \n","                    target_index = target[0]\n","                    target_label = target[1]         \n","\n","\n","                    neighbors = g.predecessors(target_index).tolist()\n","                    intersection = list(set(co_changed_data)&set(list(neighbors)))\n","                    co_change_embedding = torch.zeros(1, h_feature)\n","                    if len(intersection) > 0:\n","                        score = 0   \n","                        target = best_h[target_index]\n","                        for index in intersection:\n","                            co_change_embedding = torch.add(co_change_embedding, best_h[index])\n","                        avg_co_change_embedding = co_change_embedding[0]/len(intersection)\n","                        dot_score = util.dot_score(avg_co_change_embedding, target)\n","                        target_score.append((float(dot_score), target_label))\n","                    else:\n","                        target_score.append((0, target_label))\n","\n","                sorted_predictions = sorted(target_score,key=lambda tup: tup[0], reverse=True)[:5]\n","                result.append(sorted_predictions)\n","        graph_result[project_name] = result\n","    return graph_result"]},{"cell_type":"code","source":["# generate the results using NeighborCounting approaches\n","def getResultNeighbor(project):\n","    dir_path = f'{base_url}/node_embedding/{project}/'\n","    projects = [f for f in listdir(dir_path) if isfile(join(dir_path, f))] \n","    project_result = {}\n","    for subproject in projects:\n","        project_name = '-'.join(subproject.split('-')[:-1])\n","        with open(f'{base_url}/gnn-graph/{project}/{project_name}-train.pkl-graph.pkl', 'rb') as f:\n","            g = pickle.load(f)\n","            g = dgl.to_networkx(g)\n","        with open(f\"{base_url}/dataset/{project}/test/{project_name}-test.pkl\", 'rb') as f:\n","            test_data = pickle.load(f)\n","            project_score = []\n","            result = []\n","            for data in test_data:\n","                co_changed_data = [element['function_idx'] for element in data[\"co-change\"]]\n","                target_data = [(element['function_idx'],element['label']) for element in data[\"to-predict\"]]\n","                \n","                target_score = []\n","                for target in target_data: \n","                    target_index = target[0]\n","                    target_label = target[1]\n","                    if target_index in g.nodes:\n","                        neighbors = list(nx.neighbors(g, target_index))\n","                        count_score = 0\n","                        for neighbor in neighbors:\n","                            if neighbor in co_changed_data:\n","                                count_score+= 1\n","                    else:\n","                        count_score = 0\n","                    target_score.append((count_score, target_label))\n","                \n","                sorted_predictions = sorted(target_score,key=lambda tup: tup[0], reverse=True)[:5]\n","                result.append(sorted_predictions)\n","        project_result[project_name] = result\n","    return project_result"],"metadata":{"id":"lJk94mJe_5Ba","executionInfo":{"status":"ok","timestamp":1683081908131,"user_tz":-600,"elapsed":5,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# generate the results using top-k recent functions approach\n","def getBaseline(project, topk):\n","    train_dir_path = f'{base_url}/dataset/{project}/train/'\n","\n","    projects = [f for f in listdir(train_dir_path) if isfile(join(train_dir_path, f))]\n","\n","    project_rec_result = {}\n","\n","    for subproject in projects:\n","      print(f\"processing {subproject}\")\n","      sorted_base_rencent = {}\n","\n","      project_recent_result = []\n","      project_name = '-'.join(subproject.split('-')[:-1])\n","      with open(f'{base_url}/dataset/{project}/train/{project_name}-train.pkl', 'rb') as f:\n","          train_data = pickle.load(f)\n","          score = 0 \n","          for review in list(train_data):\n","              for function in review:\n","                  label = function[\"label\"]\n","                  code = function[\"code\"]\n","                  if label == 1:\n","                      sorted_base_rencent[code] = score\n","              score += 1\n","\n","      with open(f'{base_url}/dataset/{project}/test/{project_name}-test.pkl', 'rb') as f:\n","          test_data = pickle.load(f)\n","          topk_recent_result = []\n","          id = 0\n","          for review in test_data:\n","              freq_result = []\n","              rec_result = []\n","              review_code = []\n","              review_label = []\n","              temp_rec = []\n","              for to_predict_data in review['to-predict']:\n","                  test_code = to_predict_data['code']\n","                  test_label = to_predict_data['label']\n","                  sorted_base_rencent_list = list(sorted_base_rencent.keys())\n","                  if test_code in sorted_base_rencent_list:\n","                      temp_rec.append((sorted_base_rencent[test_code],test_label))\n","                  else:\n","                      temp_rec.append((0,0))\n","              temp_rec = sorted(temp_rec, key=lambda tup:tup[0], reverse=True)[:topk]\n","              topk_recent_result.append(temp_rec)\n","              \n","              id += 1\n","      project_rec_result[project_name] = topk_recent_result\n","\n","    return project_rec_result"],"metadata":{"id":"Tr2FT7JA0RRj","executionInfo":{"status":"ok","timestamp":1683081908131,"user_tz":-600,"elapsed":5,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Top-k accuracy evaluation metric"],"metadata":{"id":"8as4w2qW5UqK"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"MIklbSl0nywp","executionInfo":{"status":"ok","timestamp":1683081908131,"user_tz":-600,"elapsed":5,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"outputs":[],"source":["def evaluateTopkAcc(result, topk):\n","    project_result = []\n","    for project in result.keys():\n","        eval_result = []\n","        for predictions in result[project]:\n","              predictons = predictions[:topk]\n","              evaluate = False\n","              for predict in predictons:\n","                  if predict[1] == 1:\n","                      evaluate = True\n","                      break\n","              if evaluate:\n","                  eval_result.append(1)\n","              else:\n","                  eval_result.append(0)\n","        project_result.append(sum(eval_result)/len(eval_result))\n","    print(statistics.median(project_result))\n","    return project_result"]},{"cell_type":"markdown","source":["MRR evaluation metric"],"metadata":{"id":"ZPdDoMGT5Xyj"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"fRXfLQnn0L35","executionInfo":{"status":"ok","timestamp":1683081908131,"user_tz":-600,"elapsed":5,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"outputs":[],"source":["def evaluateMRR(result, topk):\n","    project_result = []\n","    for project in result.keys():\n","        eval_result = []\n","        for predictions in result[project]:\n","              predict_k = predictions[:topk]\n","              true_index = -1\n","              for n in range(len(predict_k)):\n","                  if predict_k[n][1] == 1:\n","                      true_index = n+1\n","                      break\n","              if true_index != -1:\n","                  eval_result.append(1/true_index)\n","              else:\n","                  eval_result.append(0)   \n","        project_result.append(sum(eval_result)/len(result[project]))\n","    print(statistics.median(project_result))\n","    return project_result"]},{"cell_type":"markdown","source":["MAP evaluation metric"],"metadata":{"id":"jkA8b8QK5Z4O"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"KjUta0onFFtV","executionInfo":{"status":"ok","timestamp":1683081908132,"user_tz":-600,"elapsed":5,"user":{"displayName":"aws research","userId":"16991543843945014661"}}},"outputs":[],"source":["def evaluateMAP(result, topk):\n","    project_result = []\n","    for project in result.keys():\n","        eval_result = []\n","        for predictions in result[project]:\n","              predict_k = predictions[:topk]\n","              ap = 0\n","              count = 0\n","              for n in range(len(predict_k)):\n","                  if predict_k[n][1] == 1:\n","                      count += 1\n","                      ap += count/(n+1)\n","              if ap:\n","                  eval_result.append(ap/count)\n","              else:\n","                  eval_result.append(0)   \n","        project_result.append(sum(eval_result)/len(result[project]))\n","\n","    print(statistics.median(project_result))\n","    return project_result"]},{"cell_type":"markdown","source":["Results evaluation"],"metadata":{"id":"dHDbdsMy5mJc"}},{"cell_type":"code","source":["from scipy.stats import ranksums\n","from pingouin import compute_effsize\n","from scipy.stats import wilcoxon\n","\n","def mergeResult(project, topk, rst_g, rst_n,rst_r):\n","    res = []\n","    if project == 'chromium':\n","        project = 'Chromium'\n","    else:\n","        project = 'Qt'\n","    for data in rst_g:\n","        res.append({'project':project,'topk':f'Best-{topk}','approach':\"CoChangeFinder\", 'result':data})\n","    for data in rst_n:\n","        res.append({'project':project,'topk':f'Best-{topk}','approach':\"NeighborCount\", 'result':data})\n","    for data in rst_r:\n","        res.append({'project':project,'topk':f'Best-{topk}','approach':\"Top-k recent\", 'result':data})\n","    return res\n","\n","\n","projects = [\"chromium\",\"qt\"]\n","\n","for project in projects:\n","    print(\"eval\", project)\n","\n","    rst_g = getResult(project)\n","    rst_n = getResultNeighbor(project)\n","    rst_rec_ba  = getBaseline(project, k)\n","\n","\n","    print(f\"\\n=== topkacc ====\")\n","    result_graph_topk = evaluateTopkAcc(rst_g, k)\n","    result_nb_topk = evaluateTopkAcc(rst_n, k)\n","    result_rec_r_topk = evaluateTopkAcc(rst_rec_ba, k)\n","    effect_size = compute_effsize(result_graph_topk, result_rec_r_topk, eftype='cohen')\n","    print(\"effect_size\", effect_size)\n","\n","    print(f\"\\n=== mrr ====\")\n","    result_graph_mrr = evaluateMRR(rst_g, k)\n","    result_nb_mrr = evaluateMRR(rst_n, k)\n","    result_rec_r_mrr = evaluateMRR(rst_rec_ba, k)\n","    effect_size = compute_effsize(result_graph_mrr, result_rec_r_mrr, eftype='cohen')\n","    print(\"effect_size\", effect_size)\n","\n","    print(f\"\\n=== map ====\")\n","    result_graph_map = evaluateMAP(rst_g, k)\n","    result_nb_map = evaluateMAP(rst_n, k)\n","    result_rec_r_map = evaluateMAP(rst_rec_ba, k)\n","    effect_size = compute_effsize(result_graph_map, result_rec_r_map, eftype='cohen')\n","    print(\"effect_size\", effect_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MsIwSHWTSbK","executionInfo":{"status":"ok","timestamp":1683082621354,"user_tz":-600,"elapsed":465375,"user":{"displayName":"aws research","userId":"16991543843945014661"}},"outputId":"4c04cd8c-3044-447a-de08-e6129a397785"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["eval chromium\n","processing chromium-angle_2Fangle-train.pkl\n","processing chromium-aosp_2Fplatform_2Fsystem_2Fupdate_engine-train.pkl\n","processing chromium-chromiumos_2Fplatform_2Fec-train.pkl\n","processing chromium-chromiumos_2Fplatform2-train.pkl\n","processing chromium-chromiumos_2Fthird_party_2Fflashrom-train.pkl\n","processing chromium-v8_2Fv8-train.pkl\n","\n","=== topkacc ====\n","0.2372448979591837\n","0.1577708006279435\n","0.06018616458641845\n","effect_size 0.9938022849629965\n","\n","=== mrr ====\n","0.15956632653061226\n","0.10828754578754579\n","0.055073690148790634\n","effect_size 1.0934771754600643\n","\n","=== map ====\n","0.1672264739229025\n","0.10842490842490843\n","0.055073690148790634\n","effect_size 1.113892396062397\n","eval qt\n","processing qt-qt_2Fqtwayland-train.pkl\n","processing qt-qt_2Fqtwebengine-train.pkl\n","processing qt-qbs_2Fqbs-train.pkl\n","processing qt-qt_2Fqtquick3d-train.pkl\n","processing qt-qt3dstudio_2Fqt3d-runtime-train.pkl\n","processing qt-qt_2Fqtbase-train.pkl\n","processing qt-installer-framework_2Finstaller-framework-train.pkl\n","processing qt-qt_2Fqtquickcontrols2-train.pkl\n","processing qt-qt3dstudio_2Fqt3dstudio-train.pkl\n","processing qt-qt_2Fqt3d-train.pkl\n","processing qt-qt-creator_2Fqt-creator-train.pkl\n","processing qt-qt_2Fqtdeclarative-train.pkl\n","\n","=== topkacc ====\n","0.2937254901960784\n","0.26324786324786326\n","0.03363127482845793\n","effect_size 1.3355188437295766\n","\n","=== mrr ====\n","0.16759259259259257\n","0.15404761904761904\n","0.022702991452991452\n","effect_size 0.9699267958492832\n","\n","=== map ====\n","0.1619553376906318\n","0.14798412698412694\n","0.02169894366197183\n","effect_size 0.9062191747904258\n"]}]},{"cell_type":"markdown","source":["Statistic of the studied dataset"],"metadata":{"id":"tYWi8MEW5tZd"}},{"cell_type":"code","source":["# Statistic of the studied dataset\n","over_all_review_train = 0\n","over_all_function_train = 0\n","over_all_review_test = 0\n","over_all_function_test_co = 0\n","over_all_function_test_to = 0\n","over_all_project = 0\n","for project in projects:\n","    train_dir_path = f'{base_url}/dataset/{project}/train/'\n","\n","    files = [f for f in listdir(train_dir_path) if isfile(join(train_dir_path, f))]\n","\n","    total_review_train = 0\n","    total_review_test = 0\n","    total_function_train = 0\n","    total_function_test_co = 0\n","    total_function_test_to = 0\n","\n","    \n","    for file in files:\n","        project_name = '-'.join(file.split('-')[:-1])\n","        with open(f'{base_url}/dataset/{project}/train/{file}', 'rb') as f:\n","            content = pickle.load(f)\n","            for review in content:\n","                total_review_train += 1\n","                for function in review:\n","                    total_function_train += 1\n","        with open(f'{base_url}/dataset/{project}/test/{project_name}-test.pkl', 'rb') as f:\n","            content = pickle.load(f)\n","            for review in content:\n","                total_review_test += 1\n","                total_function_test_co += len(review['co-change'])\n","                total_function_test_to += len(review['to-predict'])\n","    print(f\"{project}, studied training:{total_review_train},studied functions:{total_function_train},studied testing:{total_review_test},changed functions:{total_function_test_co},preseved function:{total_function_test_to}, project_num:{len(files)}\")\n","    over_all_review_train += total_review_train\n","    over_all_function_train += total_function_train\n","    over_all_review_test += total_review_test\n","    over_all_function_test_co += total_function_test_co\n","    over_all_function_test_to += total_function_test_to\n","    over_all_project += len(files)\n","print(\"total\",over_all_review_train,over_all_function_train,over_all_review_test,over_all_function_test_co,over_all_function_test_to,over_all_project)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuWh1YculB7U","executionInfo":{"status":"ok","timestamp":1682390349602,"user_tz":-600,"elapsed":501,"user":{"displayName":"aws research","userId":"16991543843945014661"}},"outputId":"b5ab8251-fdbb-41a9-a859-e17788a02931"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["chromium, studied training:5729,studied functions:75728,studied testing:383,changed functions:3406,preseved function:72334, project_num:6\n","qt, studied training:12317,studied functions:206403,studied testing:686,changed functions:7925,preseved function:118545, project_num:12\n","total 18046 282131 1069 11331 190879 18\n"]}]},{"cell_type":"markdown","source":["Design challenge"],"metadata":{"id":"wDP6L_fn5wn-"}},{"cell_type":"code","source":["#Design challenge\n","import statistics\n","for project in projects:\n","    train_dir_path = f'{base_url}/dataset/{project}/train/'\n","\n","    files = [f for f in listdir(train_dir_path) if isfile(join(train_dir_path, f))]\n","\n","    result = []\n","    for file in files:\n","        project_name = '-'.join(file.split('-')[:-1])\n","        with open(f'{base_url}/dataset/{project}/train/{file}', 'rb') as f:\n","            train_data = pickle.load(f)\n","        with open(f\"{base_url}/dataset/{project}/test/{project_name}-test.pkl\", 'rb') as f:\n","            test_data = pickle.load(f)\n","        \n","        train_code_list = []\n","        exist_idx = []\n","        for review in train_data:\n","            for function in review:\n","                function_name = function['function_name']\n","                function_code = function['code']\n","                file_name = '-'.join(function['file'].split('-')[1:-1])\n","                unique_string = function_name + function_code + file_name\n","                train_code_list.append(unique_string)\n","        count = 0\n","        test_funciton = 0\n","        for review in test_data:\n","            co_changed = review['co-change']\n","            to_predict = review['to-predict']\n","            test_funciton += len(co_changed)\n","            test_funciton += len(to_predict)\n","            for function in co_changed:\n","                function_name = function['function_name']\n","                function_code = function['code']\n","                file_name = '-'.join(function['file'].split('-')[1:-1])\n","                unique_string = function_name + function_code + file_name\n","                if unique_string not in train_code_list:\n","                    count += 1\n","                else:\n","                    exist_idx.append(function['function_idx'])\n","            for function in to_predict:\n","                function_name = function['function_name']\n","                function_code = function['code']\n","                file_name = '-'.join(function['file'].split('-')[1:-1])\n","                unique_string = function_name + function_code + file_name\n","                if unique_string not in train_code_list:\n","                    count += 1\n","                else:\n","                    exist_idx.append(function['function_idx'])\n","        # print(project_name,count, test_funciton, len(exist_idx))\n","        result.append(count/test_funciton)\n","    print(f\"median of percentage test data not in train dataset for {project}\", statistics.median(result))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcMpZ8IvlRAw","executionInfo":{"status":"ok","timestamp":1682390432106,"user_tz":-600,"elapsed":82186,"user":{"displayName":"aws research","userId":"16991543843945014661"}},"outputId":"367f8321-0766-4536-99ca-871226237803"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["median of percentage test data not in train dataset for chromium 0.8232816056575952\n","median of percentage test data not in train dataset for qt 0.8223450814771656\n"]}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOa6iFsledeIzZjMjKT1AAp"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}